{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53128654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Guardadas 15 columnas en training_columns.json\n",
      "Dimensiones de entrenamiento: (734, 15)\n",
      "Dimensiones de prueba: (184, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import joblib\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(r\"C:\\Users\\johan\\OneDrive - Universidad del Norte\\Escritorio\\MachineLearning\\heart-disease-mlops\\heart.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: No se encontró 'heart.csv'.\")\n",
    "\n",
    "\n",
    "df_encoded = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "X = df_encoded.drop(\"HeartDisease\", axis=1)\n",
    "y = df_encoded[\"HeartDisease\"]\n",
    "\n",
    "cols = X.columns.tolist()\n",
    "with open(\"training_columns.json\", \"w\") as f:\n",
    "    json.dump(cols, f)\n",
    "\n",
    "print(f\"✅ Guardadas {len(cols)} columnas en training_columns.json\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Dimensiones de entrenamiento:\", X_train.shape)\n",
    "print(\"Dimensiones de prueba:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec622cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipeline(model, param_grid, X_train, y_train, X_test, y_test):\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", MinMaxScaler()),\n",
    "        (\"clf\", model)\n",
    "    ])\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        pipe,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring=\"roc_auc\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = grid.predict(X_test)\n",
    "    \n",
    "    if hasattr(grid.best_estimator_, \"predict_proba\"):\n",
    "        y_prob = grid.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_prob)\n",
    "    else:\n",
    "        try:\n",
    "            y_prob_decision = grid.decision_function(X_test)\n",
    "            auc = roc_auc_score(y_test, y_prob_decision)\n",
    "        except AttributeError:\n",
    "            auc = np.nan\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"--- Modelo: {model.__class__.__name__} ---\")\n",
    "    print(f\"Mejor AUC: {auc:.4f}\")\n",
    "    print(f\"Mejor Acc: {acc:.4f}\")\n",
    "    print(f\"Mejores Parámetros: {grid.best_params_}\\n\")\n",
    "\n",
    "    return {\n",
    "        \"modelo\": model.__class__.__name__,\n",
    "        \"mejor_auc\": auc,\n",
    "        \"mejor_acc\": acc,\n",
    "        \"mejores_param\": grid.best_params_,\n",
    "        \"mejor_modelo\": grid.best_estimator_\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75b3b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [\n",
    "    {\n",
    "        \"modelo\": LogisticRegression(max_iter=1000, solver='liblinear'),\n",
    "        \"param_grid\": {\n",
    "            \"clf__penalty\": ['l1', 'l2'],\n",
    "            \"clf__C\": [0.01, 0.1, 1, 10]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"modelo\": RandomForestClassifier(random_state=42),\n",
    "        \"param_grid\": {\n",
    "            \"clf__n_estimators\": [100, 200],\n",
    "            \"clf__max_depth\": [5, 10, None]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"modelo\": KNeighborsClassifier(),\n",
    "        \"param_grid\": {\n",
    "            \"clf__n_neighbors\": [3, 5, 7, 9]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"modelo\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "        \"param_grid\": {\n",
    "            \"clf__n_estimators\": [100, 200],\n",
    "            \"clf__learning_rate\": [0.01, 0.1],\n",
    "            \"clf__max_depth\": [3, 5]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"modelo\": GaussianNB(),\n",
    "        \"param_grid\": {\n",
    "            \"clf__var_smoothing\": [1e-9, 1e-8, 1e-7] \n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"modelo\": RidgeClassifier(random_state=42),\n",
    "        \"param_grid\": {\n",
    "            \"clf__alpha\": [0.1, 1.0, 10.0]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c67decf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Modelo: LogisticRegression ---\n",
      "Mejor AUC: 0.9257\n",
      "Mejor Acc: 0.8533\n",
      "Mejores Parámetros: {'clf__C': 1, 'clf__penalty': 'l2'}\n",
      "\n",
      "--- Modelo: RandomForestClassifier ---\n",
      "Mejor AUC: 0.9300\n",
      "Mejor Acc: 0.8587\n",
      "Mejores Parámetros: {'clf__max_depth': 5, 'clf__n_estimators': 100}\n",
      "\n",
      "--- Modelo: KNeighborsClassifier ---\n",
      "Mejor AUC: 0.9164\n",
      "Mejor Acc: 0.8370\n",
      "Mejores Parámetros: {'clf__n_neighbors': 9}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "1 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 662, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1580, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 603, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1065, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\core.py\", line 1573, in __init__\n",
      "    self._init(\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\core.py\", line 1632, in _init\n",
      "    it.reraise()\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\core.py\", line 569, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\core.py\", line 550, in _handle_exception\n",
      "    return fn()\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\core.py\", line 637, in <lambda>\n",
      "    return self._handle_exception(lambda: self.next(input_data), 0)\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\data.py\", line 1402, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\core.py\", line 626, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\core.py\", line 954, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\core.py\", line 1092, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\data.py\", line 1348, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\data.py\", line 679, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\data.py\", line 1279, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:59:45] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\data\\array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 2) : \n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.90724453        nan 0.90328715 0.90950871 0.92933925 0.92326137\n",
      " 0.91545166 0.91655618]\n",
      "  warnings.warn(\n",
      "c:\\Users\\johan\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:59:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Modelo: XGBClassifier ---\n",
      "Mejor AUC: 0.9334\n",
      "Mejor Acc: 0.8804\n",
      "Mejores Parámetros: {'clf__learning_rate': 0.1, 'clf__max_depth': 3, 'clf__n_estimators': 100}\n",
      "\n",
      "--- Modelo: GaussianNB ---\n",
      "Mejor AUC: 0.9302\n",
      "Mejor Acc: 0.8587\n",
      "Mejores Parámetros: {'clf__var_smoothing': 1e-09}\n",
      "\n",
      "--- Modelo: RidgeClassifier ---\n",
      "Mejor AUC: 0.9239\n",
      "Mejor Acc: 0.8370\n",
      "Mejores Parámetros: {'clf__alpha': 0.1}\n",
      "\n",
      "=== Resultados Finales de la Competición ===\n",
      "                   modelo  mejor_auc  mejor_acc  \\\n",
      "3           XGBClassifier   0.933366   0.880435   \n",
      "4              GaussianNB   0.930210   0.858696   \n",
      "1  RandomForestClassifier   0.929967   0.858696   \n",
      "0      LogisticRegression   0.925719   0.853261   \n",
      "5         RidgeClassifier   0.923899   0.836957   \n",
      "2    KNeighborsClassifier   0.916434   0.836957   \n",
      "\n",
      "                                       mejores_param  \n",
      "3  {'clf__learning_rate': 0.1, 'clf__max_depth': ...  \n",
      "4                      {'clf__var_smoothing': 1e-09}  \n",
      "1    {'clf__max_depth': 5, 'clf__n_estimators': 100}  \n",
      "0                {'clf__C': 1, 'clf__penalty': 'l2'}  \n",
      "5                                {'clf__alpha': 0.1}  \n",
      "2                            {'clf__n_neighbors': 9}  \n"
     ]
    }
   ],
   "source": [
    "resultados = []\n",
    "\n",
    "for m in modelos:\n",
    "    r = train_pipeline(m[\"modelo\"], m[\"param_grid\"], X_train, y_train, X_test, y_test)\n",
    "    resultados.append(r)\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados).sort_values(by=\"mejor_auc\", ascending=False, na_position='last')\n",
    "\n",
    "print(\"=== Resultados Finales de la Competición ===\")\n",
    "print(df_resultados[['modelo', 'mejor_auc', 'mejor_acc', 'mejores_param']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0e20e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Modelo exportado en: c:\\Users\\johan\\OneDrive - Universidad del Norte\\Escritorio\\MachineLearning\\heart-disease-mlops\\model.joblib\n",
      "✅ Columnas exportadas en: c:\\Users\\johan\\OneDrive - Universidad del Norte\\Escritorio\\MachineLearning\\heart-disease-mlops\\training_columns.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import joblib \n",
    "\n",
    "best_model_pipeline = df_resultados.iloc[0][\"mejor_modelo\"]\n",
    "best_model_name = df_resultados.iloc[0][\"modelo\"]\n",
    "\n",
    "# --- Ambas rutas deben apuntar a la raíz (../) ---\n",
    "output_path_model = \"../model.joblib\"\n",
    "output_path_cols = \"../training_columns.json\"\n",
    "\n",
    "# Guardar el modelo\n",
    "joblib.dump(best_model_pipeline, output_path_model)\n",
    "\n",
    "# Guardar las columnas\n",
    "with open(output_path_cols, \"w\") as f:\n",
    "    json.dump(cols, f)\n",
    "\n",
    "print(f\"\\n✅ Modelo exportado en: {os.path.abspath(output_path_model)}\")\n",
    "print(f\"✅ Columnas exportadas en: {os.path.abspath(output_path_cols)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
